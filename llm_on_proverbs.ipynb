{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBSKYO34kjpC"
      },
      "outputs": [],
      "source": [
        "!pip install pandas openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "id": "nPXYYSyjroo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import re"
      ],
      "metadata": {
        "id": "uWDS4Ab-gBrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the file is uploaded to Colab storage\n",
        "file_path = '/content/data.xlsx'\n",
        "\n",
        "# Load the Excel file into a DataFrame\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Create a list of tuples for each row to preserve order\n",
        "data_list = [tuple(row) for row in df.values]"
      ],
      "metadata": {
        "id": "OxBRocwYnagJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new list to hold the formatted strings along with the correct answer\n",
        "formatted_list_with_answers = []\n",
        "\n",
        "# Iterate through each tuple in data_list\n",
        "for dialogue, answers, correct_answer in data_list:\n",
        "    formatted_string = (\n",
        "        \"Part of the dialogue is written here. You need to analyze it and choose one of the four options listed below, \"\n",
        "        \"which you consider to be the most correct based on the dialogue.\\n\\n\"\n",
        "        f\"{dialogue}\\n\\n\"\n",
        "        \"Choose one correct option out of four:\\n\"\n",
        "        f\"{answers}\"\n",
        "    )\n",
        "    formatted_list_with_answers.append((formatted_string, correct_answer))"
      ],
      "metadata": {
        "id": "lSLSzG1JgM9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Together API key\n",
        "TOGETHER_API_KEY = \"\""
      ],
      "metadata": {
        "id": "hiLY6tL9qoWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to send a prompt to the Together.ai API\n",
        "def send_prompt_to_together(prompt):\n",
        "    url = \"https://api.together.xyz/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_tokens\": 50\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "NVonHRtjri7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New list to hold the responses\n",
        "response_list = []\n",
        "\n",
        "# Delay between requests to stay within rate limit\n",
        "delay_between_requests = 1.5  # 1.5 seconds to ensure we don't hit the rate limit\n",
        "\n",
        "# Send each formatted dialogue and answers as a prompt and save the response\n",
        "for formatted_string, correct_answer in formatted_list_with_answers:\n",
        "    response = send_prompt_to_together(formatted_string)\n",
        "    if response:\n",
        "        choices = response.get('choices', [])\n",
        "        if choices:\n",
        "            response_message = choices[0]['message']['content']\n",
        "            print(f\"Response: {choices[0]['message']['content']}\")\n",
        "            response_list.append((formatted_string, response_message, correct_answer))\n",
        "        else:\n",
        "            print(\"No choices returned in the response.\")\n",
        "            response_list.append((formatted_string, None, correct_answer))\n",
        "    else:\n",
        "        print(\"Failed to get a response from the API.\")\n",
        "        response_list.append((formatted_string, None, correct_answer))\n",
        "\n",
        "    # Delay to avoid rate limiting\n",
        "    time.sleep(delay_between_requests)\n"
      ],
      "metadata": {
        "id": "FpkCLLATw_TP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the response list to verify\n",
        "for item in response_list:\n",
        "    print(f\"Formatted String: {item[0]}\")\n",
        "    print(f\"Response: {item[1]}\")\n",
        "    print(f\"Correct Answer: {item[2]}\")\n",
        "    print(\"-----\")"
      ],
      "metadata": {
        "id": "gVHAWY26yX76",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_response_characters(response_list):\n",
        "    \"\"\"\n",
        "    Remove all characters except for the one immediately preceding each ')' in the 'response' field of the response_list.\n",
        "\n",
        "    Parameters:\n",
        "    response_list (list): A list of tuples, where each tuple contains:\n",
        "                          (formatted_string, response, correct_answer)\n",
        "\n",
        "    Returns:\n",
        "    list: A new list with cleaned 'response' fields.\n",
        "    \"\"\"\n",
        "    cleaned_response_list = []\n",
        "\n",
        "    for formatted_string, response, correct_answer in response_list:\n",
        "        if response:\n",
        "            # Check if there is a ')' in the response\n",
        "            if ')' in response:\n",
        "                # Find the character immediately before the last ')'\n",
        "                last_char_before_parenthesis = re.findall(r'.(?=\\))', response)[-1]\n",
        "                cleaned_response = last_char_before_parenthesis\n",
        "            else:\n",
        "                # If there is no ')', replace with 'x'\n",
        "                cleaned_response = 'x'\n",
        "            cleaned_response_list.append((formatted_string, cleaned_response, correct_answer))\n",
        "        else:\n",
        "            cleaned_response_list.append((formatted_string, 'x', correct_answer))\n",
        "\n",
        "    return cleaned_response_list"
      ],
      "metadata": {
        "id": "k5le5GZcIcFy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_response_list = clean_response_characters(response_list)"
      ],
      "metadata": {
        "id": "77JWdu6yg5Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the cleaned response list to verify\n",
        "for item in cleaned_response_list:\n",
        "    print(f\"Prompt: {item[0]}\")\n",
        "    print(f\"Response: {item[1]}\")\n",
        "    print(f\"Correct Answer: {item[2]}\")\n",
        "    print(\"-----\")"
      ],
      "metadata": {
        "id": "jVih0umLg7eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(response_list):\n",
        "    \"\"\"\n",
        "    Calculate the accuracy of the responses compared to the correct answers.\n",
        "\n",
        "    Parameters:\n",
        "    response_list (list): A list of tuples, where each tuple contains:\n",
        "                          (formatted_string, response, correct_answer)\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy as a percentage of correct responses.\n",
        "    \"\"\"\n",
        "    correct_count = 0\n",
        "    total_count = len(response_list)\n",
        "\n",
        "    for item in response_list:\n",
        "        _, response, correct_answer = item\n",
        "\n",
        "        if response and response.strip().lower() == correct_answer.strip().lower():\n",
        "            correct_count += 1\n",
        "\n",
        "    accuracy = (correct_count / total_count) * 100\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "o1cCzCyrC93c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage with the cleaned_response_list\n",
        "accuracy = calculate_accuracy(cleaned_response_list)\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "Hd2ppnnoDUBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_responses_to_excel(file_path, response_list):\n",
        "    \"\"\"\n",
        "    Add a 'response' column to the Excel file with the responses from the response list.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): The path to the Excel file.\n",
        "    response_list (list): A list of tuples, where each tuple contains:\n",
        "                          (formatted_string, response, correct_answer)\n",
        "    \"\"\"\n",
        "    # Load the Excel file into a DataFrame\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Check if the length of the DataFrame matches the length of the response list\n",
        "    if len(df) != len(response_list):\n",
        "        raise ValueError(\"The length of the DataFrame does not match the length of the response list.\")\n",
        "\n",
        "    # Add the 'response' column to the DataFrame\n",
        "    df['LLaMA-2 Chat (13B)'] = [response[1] for response in response_list]\n",
        "\n",
        "    # Save the updated DataFrame back to the Excel file\n",
        "    df.to_excel(file_path, index=False)\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/data.xlsx'\n",
        "add_responses_to_excel(file_path, cleaned_response_list)\n",
        "\n",
        "# Verify the updated file\n",
        "updated_df = pd.read_excel(file_path)\n",
        "print(updated_df.head())"
      ],
      "metadata": {
        "id": "IHAxXgbRDeRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}